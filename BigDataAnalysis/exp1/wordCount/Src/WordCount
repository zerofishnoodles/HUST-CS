import threading
import os
from time import time


class MapThread(threading.Thread):

    def __init__(self, thread_id, source_file, target_file):
        super(MapThread, self).__init__()
        self.thread_id = thread_id
        self.source_file = source_file
        self.target_file = target_file
        self.combine_dict = {}

    def run(self) -> None:
        print("run map thread" + str(self.thread_id))
        start_time = time()
        self.mapper()
        self.combiner()
        self.shuffle()
        end_time = time()
        print("MapThread {} done, use time {}".format(self.thread_id, end_time - start_time))

    def mapper(self):
        with open(self.source_file, "r") as rf:
            with open(self.target_file + "_temp", "w") as wf:
                for line in rf:
                    line_list = line.strip().split(',')
                    for word in line_list:
                        word = word.strip()
                        self.combine_dict[word] = 0
                        wf.write(word + "\t1\n")

    def combiner(self):
        with open(self.target_file + "_temp", "r") as rf:
            with open(self.target_file, "w") as wf:
                for line in rf:
                    word = line.strip().split()[0]
                    self.combine_dict[word] += 1
                for item in self.combine_dict.items():
                    wf.write(str(item[0]) + "\t" + str(item[1]))

    def shuffle(self):
        w1 = open(reduce_pre_dir + "reduce1", "a")
        w2 = open(reduce_pre_dir + "reduce2", "a")
        w3 = open(reduce_pre_dir + "reduce3", "a")
        word_count = 0
        total_word_count = len(self.combine_dict.keys())
        for word in sorted(self.combine_dict.keys()):
            line = word + "\t" + str(self.combine_dict[word]) + "\n"
            if not line[0].isalpha() or line[0] < 'd':
                thread_lock.acquire()
                w1.write(line)
                thread_lock.release()
            elif line[0]<'p':
                thread_lock.acquire()
                w2.write(line)
                thread_lock.release()
            else:
                thread_lock.acquire()
                w3.write(line)
                thread_lock.release()
            # if word_count>=0 and word_count<=total_word_count/3:
            #     thread_lock.acquire()
            #     w1.write(line)
            #     thread_lock.release()
            # elif word_count>total_word_count/3 and word_count<total_word_count*2/3:
            #     thread_lock.acquire()
            #     w2.write(line)
            #     thread_lock.release()
            # else:
            #     thread_lock.acquire()
            #     w3.write(line)
            #     thread_lock.release()
            word_count += 1
        w1.close()
        w2.close()
        w3.close()


class ReduceThread(threading.Thread):
    def __init__(self, thread_id, source_file, target_file):
        super(ReduceThread, self).__init__()
        self.thread_id = thread_id
        self.source_file = source_file
        self.target_file = target_file
        self.reduce_dict = {}

    def run(self) -> None:
        print("run reduce thread" + str(self.thread_id))
        start_time = time()
        self.reducer()
        end_time = time()
        print("ReduceThread {} done, use time {}".format(self.thread_id, end_time - start_time))

    def reducer(self):
        with open(self.source_file, "r") as rf:
            with open(self.target_file, "w") as wf:
                for line in rf:
                    word_count = line.strip().split()
                    if word_count[0] in self.reduce_dict:
                        self.reduce_dict[word_count[0]] += int(word_count[1])
                    else:
                        self.reduce_dict[word_count[0]] = int(word_count[1])
                for item in self.reduce_dict.items():
                    line = item[0] + "\t" + str(item[1]) + "\n"
                    wf.write(line)


if __name__ == '__main__':
    work_dir = os.path.dirname(os.getcwd())
    source_dir = work_dir + "/Data/"
    mapper_dir = work_dir + "/MapResult/"
    reduce_pre_dir = work_dir + "/ReducePre/"
    reducer_dir = work_dir + "/ReduceResult/"

    thread_lock = threading.Lock()
    map_thread_pool = []
    for thread_id in range(1, 10):
        thread = MapThread(thread_id, source_dir + "source0" + str(thread_id), mapper_dir + "map0" + str(thread_id))
        thread.start()
        map_thread_pool.append(thread)

    for thread in map_thread_pool:
        thread.join()

    print("map end!")

    reduce_thread_pool = []
    for thread_id in range(1, 4):
        thread = ReduceThread(thread_id, reduce_pre_dir + "reduce" + str(thread_id), reducer_dir + "reduce" + str(thread_id))
        thread.start()
        reduce_thread_pool.append(thread)

    for thread in reduce_thread_pool:
        thread.join()

    print("reduce end!")

    file_list = os.listdir(reducer_dir)
    word_count = {}
    with open(reducer_dir+"total", "w") as wf:
        for file in file_list:
            with open(reducer_dir+file, "r") as rf:
                for line in rf:
                    words = line.strip().split()
                    if words[0] in word_count:
                        word_count[words[0]] += words[1]
                    else:
                        word_count[words[0]] = words[1]
        for key in sorted(word_count.keys()):
            line = key + "\t" + str(word_count[key]) + "\n"
            wf.write(line)

    print("MapReduce end!")